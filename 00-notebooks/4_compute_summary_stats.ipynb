{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678bd15b-11be-4e4b-941d-92f9bacc4527",
   "metadata": {},
   "source": [
    "# Compute summary statistics of LST and NDVI\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Having computed LST and NDVI in NYC, we compute summary statistics within HOLC grades. We find \n",
    "\n",
    "- mean\n",
    "- median\n",
    "- minimum\n",
    "- maximum\n",
    "- standard deviation\n",
    "- number of clear pixels (The number of clear pixels is an integer representing the number of values in a HOLC boundary that are not `NaN`.)\n",
    "\n",
    "of the LST and NDVI within every HOLC boundary and save the results to a CSV file. We do this for every clipped LST and NDVI file, so we end up with a CSV containing summary statistics for each. These files are \n",
    "\n",
    "In a second iteration of this notebook, we found that it is advantageous to invoke a cloud filtering process to omit HOLC boundaries which are more than 10% covered by clouds. In [Section 2](#pixelnum) we reprocess the summary statistics data and add a column for the fraction of uncovered pixels called `pixel_frac`. We export these files to the same `summary_stats_agg/` folder with the prefix \"ext_ndvi_filt_**FILTER-VALUE**...\". (Naming conventions are in the Data section of this header.)\n",
    "\n",
    "We then aggregate the summary statistics in several ways:\n",
    "\n",
    "- [Method 1](#method1): For every Landsat file, we compute the mean of each summary statistic for every HOLC grade. We end up with one number representing the mean of the median LST/NDVI in HOLC grades A through D for a specific Landsat scene. (We also have the mean of the minimum, mean of the maximum, etc.) We additionally group by NYC borough and compute the mean of each summary statistic. \n",
    "- [Method 2](#method2): Since we want a representative value for the LST in an HOLC boundary over a decade, we collect all of the Landsat scenes within a date range. We then  calculate the mean of the median LST value of a single HOLC boundary within that scene. We then take the mean of those means to obtain value for the expected LST in that decade. \n",
    "- [Method 3](#method3): Collect all the HOLC_X boundaries within a decade and compute the median pixel for each. Then, calculate the mean of the median pixel to get the expected LST within a decade. This differes\n",
    "- [Method 4](#method4): Instead of taking the means of median values as we did in Methods 2 and 3, we collect all of the summary statistics within a certain date range into four large files. By computing values in this way, we work with the raw data. \n",
    "\n",
    "## Results\n",
    "\n",
    "Summary statistics are computed and exported to the `02-data/` folder. \n",
    "\n",
    "## Data\n",
    "\n",
    "Two types of data are imported: (i) raster data, which comes from LST and NDVI computations obtained from Landsat and (ii) shapefiles specifying HOLC boundaries. All files are imported and exported from the `02-data/` directory. Shapefiles are imported from `boundaries/holc_nyc/` and LST/NDVI files are imported from `lst_clipped_nyc/`/`ndvi_clipped_nyc`.\n",
    "\n",
    "Summary statistics are exported as CSV files to two different directories. First, summary statistics for every LST/NDVI file containing information for every HOLC boundary is exported to `summary_stats/`. The number of files in this folder should match the total sum of files in `lst_clipped_nyc/` and `ndvi_clipped_nyc`. Then the results are aggregated and exported to `summary_stats_agg/` and `summary_stats_temporal/`.\n",
    "\n",
    "| Description | Location | Data type | Naming convention | \n",
    "|--|-----|--|------|\n",
    "| LST | `lst_clipped_nyc/` | TIF | \"lst_**LANDSAT-IDENTIFIER**.TIF\" |\n",
    "| NDVI | `ndvi_clipped_nyc/` | TIF | \"ndvi_**LANDSAT-IDENTIFIER**.TIF\" |\n",
    "| Summary statistics | `summary_stats` | CSV | \"stats_lst_**LANDSAT-IDENTIFIER**.csv\" and \"stats_ndvi_**LANDSAT-IDENTIFIER**.csv\" |\n",
    "| Extended summary statistics | `summary_stats` | CSV | \"ext_lst_filt_**FILTER-VALUE**_ stats_lst_**LANDSAT-IDENTIFIER**.csv\" and \"ext_ndvi_filt_**FILTER-VALUE**_ stats_lst_**LANDSAT-IDENTIFIER**.csv\"|\n",
    "| Aggregated summary statisitics | `summary_stats_agg` | CSV | `lst_mean_stats_combined` and `ndvi_mean_stats_combined`. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae377929-0a64-4a66-a5da-0a4ab753ecc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYStatenIsland1940 ,  66\n",
      "NYManhattan1937 , Number of boundaries =  53\n",
      "NYBronx1938 , Number of boundaries =  44\n",
      "NYQueens1938 , Number of boundaries =  168\n",
      "NYBrooklyn1938 , Number of boundaries =  66\n",
      "\n",
      "\n",
      "Grade  A  has 16 boundaries and a total area of 18.630957718439234 km^2\n",
      "Grade  B  has 72 boundaries and a total area of 120.48137553473349 km^2\n",
      "Grade  C  has 189 boundaries and a total area of 389.53659708482655 km^2\n",
      "Grade  D  has 119 boundaries and a total area of 223.57670025065053 km^2\n",
      "\n",
      "Number of LST and NDVI files =  228\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "DIR_PARENT = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DIR_SCRIPTS = DIR_PARENT + \"/01-scripts\"\n",
    "\n",
    "\"\"\"Push directory to helper scripts from\"\"\"\n",
    "import sys\n",
    "sys.path.append(DIR_SCRIPTS)\n",
    "\n",
    "import helpers\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR_DATA = DIR_PARENT + \"/02-data\"\n",
    "\n",
    "DIR_STATS = DIR_DATA + \"/summary_stats\"\n",
    "DIR_STATS_AGG = DIR_DATA + \"/summary_stats_agg\"\n",
    "DIR_STATS_T = DIR_DATA + \"/summary_stats_temporal\"\n",
    "\n",
    "DIR_BOUNDARIES = DIR_DATA + \"/boundaries\"\n",
    "DIR_BOUNDARIES_HOLC = DIR_BOUNDARIES + \"/holc_nyc\"\n",
    "\n",
    "# Export directories\n",
    "DIR_NDVI_CLIPPED_NYC = DIR_PARENT + \"/02-data/ndvi_clipped_nyc\"\n",
    "DIR_LST_CLIPPED_NYC = DIR_PARENT + \"/02-data/lst_clipped_nyc\"\n",
    "DIR_FIGS = DIR_PARENT + \"/03-figs\"\n",
    "\n",
    "keys_stats = [\"median\",\"mean\",\"min\",\"max\",\"std\",\"num_pixels\"]\n",
    "\n",
    "def compute_stats(clipped_file):\n",
    "    stats = {\"median\": clipped_file.median().values,\n",
    "            \"mean\": clipped_file.mean().values,\n",
    "            \"min\": clipped_file.min().values,\n",
    "            \"max\": clipped_file.max().values,\n",
    "            \"std\": clipped_file.std().values,\n",
    "            \"num_pixels:\": np.count_nonzero(~np.isnan(clipped_file))}\n",
    "    return stats\n",
    "\n",
    "def get_row_df(df, row_loc):\n",
    "    return df[df.index==row_loc]\n",
    "\n",
    "def parse_date_fname(fname):\n",
    "    \"\"\"Parse the datetime from the summary statisics filename\"\"\"\n",
    "    return pd.to_datetime(fname.split(\"_\")[8])\n",
    "def datetime_year(y): \n",
    "    return pd.to_datetime(\"1Jan\"+str(y))\n",
    "\n",
    "\"\"\"Get all the clipped LST and NDVI filenames\n",
    "Calling get_filenames twice compiles all the filenames to one list.\"\"\"\n",
    "clipped_filenames = []\n",
    "helpers.get_filenames(DIR_LST_CLIPPED_NYC, clipped_filenames)\n",
    "helpers.get_filenames(DIR_NDVI_CLIPPED_NYC, clipped_filenames)\n",
    "\n",
    "\"\"\"Get the CRS from landsat\"\"\"\n",
    "crs_landsat = rxr.open_rasterio(clipped_filenames[0], \n",
    "                                masked=True).rio.crs\n",
    "\n",
    "\"\"\"Get all filenames of HOLC shapefiles\"\"\"\n",
    "shapefile_names_holc = []\n",
    "helpers.get_filenames(DIR_BOUNDARIES_HOLC, shapefile_names_holc)\n",
    "shapefile_names_holc = [x for x in shapefile_names_holc if \".shp\" in x]\n",
    "\n",
    "\"\"\"Initialize a dataframe to store all the HOLC information\"\"\"\n",
    "df_holc = gpd.read_file(shapefile_names_holc[0])\n",
    "df_holc = df_holc.to_crs(crs_landsat)\n",
    "df_holc[\"loc_year\"] = shapefile_names_holc[0].split(\"/\")[-2]\n",
    "print(shapefile_names_holc[0].split(\"/\")[-2], \", \", len(df_holc))\n",
    "\n",
    "for fn in shapefile_names_holc[1:]:\n",
    "    df = gpd.read_file(fn)\n",
    "    df = df.to_crs(crs_landsat)\n",
    "    boro_year = fn.split(\"/\")[-2]\n",
    "    df[\"loc_year\"] = boro_year\n",
    "    print(boro_year, \", Number of boundaries = \", len(df))\n",
    "    df_holc = df_holc.append(df)\n",
    "\n",
    "df_holc.reset_index(inplace=True)\n",
    "\n",
    "print(\"\\n\")\n",
    "for holc_grade in [\"A\",\"B\",\"C\",\"D\"]:\n",
    "    holc_geos = df_holc[df_holc[\"holc_grade\"]==holc_grade][\"geometry\"]\n",
    "    # Convert to a CRS that uses meters to measure area:\n",
    "    holc_geos = holc_geos.to_crs(3857)\n",
    "    tot_area = sum(holc_geos.apply(lambda x: x.area))\n",
    "    print(\"Grade \", holc_grade, \" has\", sum(df_holc[\"holc_grade\"]==holc_grade), \n",
    "         \"boundaries and a total area of\",tot_area/1000**2, \"km^2\")\n",
    "\n",
    "print(\"\\nNumber of LST and NDVI files = \",len(clipped_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b182f-774d-487c-bb96-faacc93e3bde",
   "metadata": {},
   "source": [
    "NYC has $~778$ km$^2$ of land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99eb798-3009-47f2-9246-d855f9836086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>holc_id</th>\n",
       "      <th>holc_grade</th>\n",
       "      <th>geometry</th>\n",
       "      <th>loc_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>43</td>\n",
       "      <td>None</td>\n",
       "      <td>E1</td>\n",
       "      <td>E</td>\n",
       "      <td>POLYGON ((596046.892 4522070.547, 596050.225 4...</td>\n",
       "      <td>NYBronx1938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  name holc_id holc_grade  \\\n",
       "162     43  None      E1          E   \n",
       "\n",
       "                                              geometry     loc_year  \n",
       "162  POLYGON ((596046.892 4522070.547, 596050.225 4...  NYBronx1938  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_holc[df_holc[\"holc_grade\"]==\"E\"] # Not sure what this is "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236df21-ba94-4859-b721-12e9ea701892",
   "metadata": {},
   "source": [
    "## 1. Compute summary statistics for every HOLC file <a id=\"summary-calc\"></a>\n",
    "\n",
    "For every clipped LST/NDVI file, we clip to each HOLC boundary and save the summary statistics for every boundary as a row in a pandas dataframe. The exported file has the form outlined in the table below. \n",
    "\n",
    "| holc_id | holc_grade | geometry | loc_year | median | mean | min | max | std | num_pixels |\n",
    "|---------|------------|----------|----------|--------|------|-----|-----|-----|-----|\n",
    "| \"boundary_id_from_source_file\" | \"holc_grade\" | holc_polygon | \"boro_identifier\" | median_pixel | mean_pixel | min_pixel | max_pixel | std_pixel | num_pixels |\n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |$\\vdots$ |$\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |\n",
    "\n",
    "**!! NOTE !!** The following cell takes a few hours to run. If you already have already computed statistics for every Landsat file, skip to the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19d0c0-e3a9-49b0-9a16-4ec5ce38ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in clipped_filenames:\n",
    "    \n",
    "    \"\"\"Initialize a DF for the HOLC data and summary statistics\"\"\"\n",
    "    df_holc_stats = df_holc.copy()\n",
    "    df_holc_stats[keys_stats] = 0.0\n",
    "\n",
    "    for index in range(len(df_holc)):\n",
    "        # For every HOLC polygon, clip the input data and compute \n",
    "        # statistic\n",
    "        boundary_holc = get_row_df(df_holc,index)[\"geometry\"]\n",
    "        \n",
    "        # Import the data that you will clip. This is either LST or NDVI data. \n",
    "        clipped = helpers.open_and_clip(fn, boundary_holc)\n",
    "\n",
    "        # ! IMPORTANT ! All values exactly equal to 0.0 are outside of \n",
    "        # the boundary. All values equal to -9999.0 were masked by the \n",
    "        # USGS. Must mask the dataframe in order for statistics to be \n",
    "        # accurate.\n",
    "        clipped_masked = clipped.where(clipped != -0.0) \n",
    "        clipped_masked = clipped_masked.where(clipped_masked != 0.0) \n",
    "        clipped_masked = clipped_masked.where(clipped_masked != -9999.0) \n",
    "\n",
    "        df_holc_stats.loc[index,keys_stats] = compute_stats(\n",
    "                clipped_masked).values()\n",
    "    \n",
    "    exportname = DIR_STATS + \"/stats_\" + fn.split(\"/\")[-1].split(\".\")[0] + \".csv\"\n",
    "    df_holc_stats = pd.DataFrame(df_holc_stats)\n",
    "    print(\"Saving \",exportname)\n",
    "    df_holc_stats.to_csv(exportname, index=False)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b46fd-de30-44da-b8ed-94522a0950c1",
   "metadata": {},
   "source": [
    "### A. Inspecting the summary statistics\n",
    "\n",
    "We would like to know if any of the predicted summary statistics are NaN, and if so why. Below, we print the summary statistics filenames which contain NaN values, and then we plot the LST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "333defc4-bc19-4f9e-8180-9f77ce2769bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filenames that contain nan median values\n",
      "/home/aderrasc/Documents/japa_final/02-data/summary_stats/stats_lst_LT05_L1TP_014032_19840921_20161004_01_T1.csv\n",
      "/home/aderrasc/Documents/japa_final/02-data/summary_stats/stats_lst_LT05_L1TP_014032_19890701_20161002_01_T1.csv\n",
      "/home/aderrasc/Documents/japa_final/02-data/summary_stats/stats_lst_LT05_L1TP_014032_19890903_20161002_01_T1.csv\n",
      "/home/aderrasc/Documents/japa_final/02-data/summary_stats/stats_lst_LT05_L1TP_014032_19950819_20160926_01_T1.csv\n",
      "/home/aderrasc/Documents/japa_final/02-data/summary_stats/stats_lst_LT05_L1TP_014032_19950904_20160926_01_T1.csv\n"
     ]
    }
   ],
   "source": [
    "# Get all the summary stats and split into NDVI and LST\n",
    "summary_names=[]\n",
    "helpers.get_filenames(DIR_STATS, summary_names)\n",
    "lst_summary_names = [x for x in summary_names if \"lst\" in x \\\n",
    "                     and \"ext\" not in x]\n",
    "ndvi_summary_names = [x for x in summary_names if \"ndvi\" in x \\\n",
    "                      and \"ext\" not in x]\n",
    "\n",
    "print(\"\\nFilenames that contain nan median values\")\n",
    "fnames_nan = []\n",
    "for fname in lst_summary_names:\n",
    "    df_stats = pd.read_csv(fname)\n",
    "    if pd.isna(df_stats[\"median\"]).any():\n",
    "        print(fname)\n",
    "        fnames_nan.append(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177c3277-bf93-4b77-9f9c-3b72b166b056",
   "metadata": {},
   "source": [
    "### Print the NaN values in the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65cf8f19-aefe-4be6-9a42-b2dce93fc0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values =  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>holc_id</th>\n",
       "      <th>holc_grade</th>\n",
       "      <th>geometry</th>\n",
       "      <th>loc_year</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>num_pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D35</td>\n",
       "      <td>D</td>\n",
       "      <td>POLYGON ((606758.6144636832 4494663.526147365,...</td>\n",
       "      <td>NYQueens1938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index name holc_id holc_grade  \\\n",
       "317    154  NaN     D35          D   \n",
       "\n",
       "                                              geometry      loc_year  median  \\\n",
       "317  POLYGON ((606758.6144636832 4494663.526147365,...  NYQueens1938     NaN   \n",
       "\n",
       "     mean  min  max  std  num_pixels  \n",
       "317   NaN  NaN  NaN  NaN         0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname_select = 1 # OPTIONS: Integer between 0 and 4\n",
    "\n",
    "####################################################\n",
    "df_stats = pd.read_csv(fnames_nan[fname_select])\n",
    "df_nans = df_stats[pd.isna(df_stats[\"median\"])]\n",
    "print(\"Number of NaN values = \", len(df_nans))\n",
    "df_nans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989b41a2-5e33-40c2-92f4-c128e5547715",
   "metadata": {},
   "source": [
    "Plot the clipped Landsat scene for these boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995f333d-99cb-4895-9d56-f7deb2c9ebe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pixels =  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Select one of the boundaries to clip to and plot\n",
    "\"\"\"\n",
    "select = 0 # OPTIONS: Integer between 0 and number of nan values-1\n",
    "\n",
    "################################################################################\n",
    "# Create the LST filename based on the summary statistics filename\n",
    "landsat_id = fnames_nan[fname_select].split(\"lst_\")[1][:-4]\n",
    "# landsat_id = lst_summary_names[fname_select].split(\"lst_\")[1][:-4]\n",
    "fname_lst = DIR_LST_CLIPPED_NYC + \"/lst_\"+landsat_id+\".tif\"\n",
    "\n",
    "# Get the HOLC ID of the boundaries which predict nan, then get the\n",
    "# geometry object form the df_holc dataframe.\n",
    "clipping_holc_id = df_nans.iloc[select][\"holc_id\"]\n",
    "clipping_boundary = df_holc[df_holc[\"holc_id\"]==clipping_holc_id][\"geometry\"]\n",
    "clipped_lst = helpers.open_and_clip(fname_lst, clipping_boundary)\n",
    "clipped_masked = clipped_lst.where(clipped_lst != -0.0) \n",
    "clipped_masked = clipped_masked.where(clipped_masked != -9999.0) \n",
    "\n",
    "print(\"Number of pixels = \", np.count_nonzero(~np.isnan(clipped_masked)))\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "im = plt.imshow(clipped_masked)#, cmap=\"RdYlBu\")#,vmin=-1,vmax=1)\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121144c-956d-4162-baec-a5fca5e502cc",
   "metadata": {},
   "source": [
    "These plots show that the NaN values are predicted when every pixel in a boundary is NaN. This motivates the measurement of the number of pixels involved in a LST/NDVI calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373df44d-9e5d-43c9-b488-b15e2a9317b1",
   "metadata": {},
   "source": [
    "## 2. Compute aggregate statistics filtered by clear pixels <a id=\"pixelnum\"></a>\n",
    "\n",
    "We would like to compute the mean of the median HOLC values for each Landsat scene, but we know that not all scenes are totally clear. Even though the Landsat files were filtered for ones with less than $10 %$ cloud cover, some HOLC boundaries my be partially or fully covered. \n",
    "\n",
    "We implement a filter to compute statistics only using boundaries that have some minimum percentage of clear pixels. We do this by \n",
    "\n",
    "1. Computing the maximum possible number of pixels in an HOLC boundary and saving the results to the `num_pixels_max` column of the dataframe `df_pixelnum`.\n",
    "2. Computing `pixel_frac` = `num_pixels`/`num_pixels_max`. \n",
    "3. Adding a new column to the the summary statistics data frame for the `pixel_frac`.\n",
    "4. Exporting an extended statistics file named \"ext_ORIGINAL-STATISTICS-FILENAME\". These files are saved to `summary_stats_agg`.\n",
    "\n",
    "### A. Compute maximum number of pixels in an HOLC grade\n",
    "\n",
    "(This takes a few minutes to complete.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ffec20-f440-4b85-824c-615fd19a5661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>holc_id</th>\n",
       "      <th>holc_grade</th>\n",
       "      <th>geometry</th>\n",
       "      <th>loc_year</th>\n",
       "      <th>num_pixels_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Randall Manor</td>\n",
       "      <td>A1</td>\n",
       "      <td>A</td>\n",
       "      <td>POLYGON ((576202.532 4499213.753, 576102.346 4...</td>\n",
       "      <td>NYStatenIsland1940</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Grymes Hill</td>\n",
       "      <td>A2</td>\n",
       "      <td>A</td>\n",
       "      <td>POLYGON ((576939.573 4496703.806, 576927.219 4...</td>\n",
       "      <td>NYStatenIsland1940</td>\n",
       "      <td>603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Todt Hill, Emmerson Hill</td>\n",
       "      <td>A3</td>\n",
       "      <td>A</td>\n",
       "      <td>POLYGON ((576032.804 4495907.753, 576293.388 4...</td>\n",
       "      <td>NYStatenIsland1940</td>\n",
       "      <td>2817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Silver Lake</td>\n",
       "      <td>A4</td>\n",
       "      <td>A</td>\n",
       "      <td>POLYGON ((576070.303 4497876.449, 576092.302 4...</td>\n",
       "      <td>NYStatenIsland1940</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>West New Brighton</td>\n",
       "      <td>B1</td>\n",
       "      <td>B</td>\n",
       "      <td>POLYGON ((574347.119 4497719.752, 574301.242 4...</td>\n",
       "      <td>NYStatenIsland1940</td>\n",
       "      <td>1124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>61</td>\n",
       "      <td>None</td>\n",
       "      <td>D5</td>\n",
       "      <td>D</td>\n",
       "      <td>POLYGON ((584855.656 4503598.365, 584611.342 4...</td>\n",
       "      <td>NYBrooklyn1938</td>\n",
       "      <td>1181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>62</td>\n",
       "      <td>None</td>\n",
       "      <td>D6</td>\n",
       "      <td>D</td>\n",
       "      <td>POLYGON ((585036.773 4505044.324, 585340.267 4...</td>\n",
       "      <td>NYBrooklyn1938</td>\n",
       "      <td>2912.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>63</td>\n",
       "      <td>None</td>\n",
       "      <td>D7</td>\n",
       "      <td>D</td>\n",
       "      <td>POLYGON ((588420.333 4503600.212, 588338.791 4...</td>\n",
       "      <td>NYBrooklyn1938</td>\n",
       "      <td>1715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>64</td>\n",
       "      <td>None</td>\n",
       "      <td>D8</td>\n",
       "      <td>D</td>\n",
       "      <td>POLYGON ((591404.017 4503718.215, 591425.947 4...</td>\n",
       "      <td>NYBrooklyn1938</td>\n",
       "      <td>7402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>65</td>\n",
       "      <td>None</td>\n",
       "      <td>D9</td>\n",
       "      <td>D</td>\n",
       "      <td>POLYGON ((585933.297 4503498.199, 586218.736 4...</td>\n",
       "      <td>NYBrooklyn1938</td>\n",
       "      <td>3288.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                      name holc_id holc_grade  \\\n",
       "0        0             Randall Manor      A1          A   \n",
       "1        1               Grymes Hill      A2          A   \n",
       "2        2  Todt Hill, Emmerson Hill      A3          A   \n",
       "3        3               Silver Lake      A4          A   \n",
       "4        4         West New Brighton      B1          B   \n",
       "..     ...                       ...     ...        ...   \n",
       "392     61                      None      D5          D   \n",
       "393     62                      None      D6          D   \n",
       "394     63                      None      D7          D   \n",
       "395     64                      None      D8          D   \n",
       "396     65                      None      D9          D   \n",
       "\n",
       "                                              geometry            loc_year  \\\n",
       "0    POLYGON ((576202.532 4499213.753, 576102.346 4...  NYStatenIsland1940   \n",
       "1    POLYGON ((576939.573 4496703.806, 576927.219 4...  NYStatenIsland1940   \n",
       "2    POLYGON ((576032.804 4495907.753, 576293.388 4...  NYStatenIsland1940   \n",
       "3    POLYGON ((576070.303 4497876.449, 576092.302 4...  NYStatenIsland1940   \n",
       "4    POLYGON ((574347.119 4497719.752, 574301.242 4...  NYStatenIsland1940   \n",
       "..                                                 ...                 ...   \n",
       "392  POLYGON ((584855.656 4503598.365, 584611.342 4...      NYBrooklyn1938   \n",
       "393  POLYGON ((585036.773 4505044.324, 585340.267 4...      NYBrooklyn1938   \n",
       "394  POLYGON ((588420.333 4503600.212, 588338.791 4...      NYBrooklyn1938   \n",
       "395  POLYGON ((591404.017 4503718.215, 591425.947 4...      NYBrooklyn1938   \n",
       "396  POLYGON ((585933.297 4503498.199, 586218.736 4...      NYBrooklyn1938   \n",
       "\n",
       "     num_pixels_max  \n",
       "0             253.0  \n",
       "1             603.0  \n",
       "2            2817.0  \n",
       "3             235.0  \n",
       "4            1124.0  \n",
       "..              ...  \n",
       "392          1181.0  \n",
       "393          2912.0  \n",
       "394          1715.0  \n",
       "395          7402.0  \n",
       "396          3288.0  \n",
       "\n",
       "[397 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Initialize a dataframe to store the maximum pixel number\"\"\"\n",
    "df_pixelnum = df_holc.copy()\n",
    "df_pixelnum[\"num_pixels_max\"] = 0.0\n",
    "\n",
    "\"\"\"\n",
    "Import an arbitrary LST file and set all its values to 1. This will\n",
    "be used to clip and determine the maximum number of non-nan values\n",
    "in a HOLC boundary.\n",
    "\"\"\"\n",
    "fn = clipped_filenames[0]\n",
    "raster = rxr.open_rasterio(fn, masked=True)\n",
    "rasterones = raster.where(type(raster) == float, 1.0).squeeze()\n",
    "\n",
    "for index in range(len(df_holc)):\n",
    "    # For every HOLC polygon, clip the raster of ones to the boundary\n",
    "    # and compute the number of nonzero elements. \n",
    "    boundary_holc = get_row_df(df_holc,index)[\"geometry\"]\n",
    "    clipped = rasterones.rio.clip(boundary_holc).squeeze()\n",
    "    df_pixelnum.loc[index,\"num_pixels_max\"] = np.count_nonzero(~np.isnan(clipped))\n",
    "\n",
    "df_pixelnum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee154a-b05a-4b8d-ac73-016a4b2b56b6",
   "metadata": {},
   "source": [
    "### B. Compute `num_pixels`/`num_pixels_max` and export extended statistics\n",
    "\n",
    "The extended statistics have the same structure as the summary statistics file described in Section 1 with the addition of a `pixel_frac` column. This column gives the fraction of pixels which are not covered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adea6915-068d-4bcd-b9ac-287b0c25c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the summary stats names\n",
    "summary_names=[]\n",
    "helpers.get_filenames(DIR_STATS, summary_names)\n",
    "\n",
    "# Make sure you're not importing the extended statistics, since those are\n",
    "# saved to the same directory\n",
    "summary_names = [x for x in summary_names if \"ext\" not in x and \".csv\" in x]\n",
    "\n",
    "for fn in summary_names:\n",
    "    \"\"\"\n",
    "    For every summary statistics file, compute the pixel_frac of clear pixels\n",
    "    and export a file called ext_.... This file condatins the same information \n",
    "    as the original statistics file, but additionally contains pixel_frac.\n",
    "    \"\"\"\n",
    "    df_summ = pd.read_csv(fn)\n",
    "    # df_summ[\"num_pixels_max\"] = df_pixelnum[\"num_pixels_max\"]\n",
    "    df_summ[\"pixel_frac\"] = df_summ[\"num_pixels\"]/df_pixelnum[\"num_pixels_max\"]\n",
    "    exportname = DIR_STATS + \"/ext_\" + fn.split(\"/\")[-1]\n",
    "    df_summ.to_csv(exportname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48254960-0aab-40e2-9703-451e136906bf",
   "metadata": {},
   "source": [
    "## 3. Aggregate Statistics\n",
    "\n",
    "We aggregate the summary statistics in several ways to analyze results temporally.\n",
    "\n",
    "### A. Method 1: By Landsat File <a id=method1></a>\n",
    "\n",
    "For LST and NDVI, we compile results into one aggregated dataframe in the following cell. The dataframe has the form \n",
    "\n",
    "| source_file | holc_grade | loc_year | median | mean | min | max | std | num_bounds |\n",
    "|-------------|------------|----------|--------|------|-----|-----|-----|-----|\n",
    "| \"name_of_source_file\"| \"grade_to_filtery_by\" | \"boro_to_filter_by\" | mean_of_medians | mean_of_mean | mean_of_min | mean_of_max | mean_of_std | num_boundaries |\n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |$\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |\n",
    "\n",
    "- `source_file` specifies the filename containing summary statistics for a single Landsat file. (These are the files exported in Section 1 of this notebook.) \n",
    "- `holc_grade` specifies the selected HOLC elements of `source_file` that are considered in the rest of the row\n",
    "- `loc_year` specifies the selected location elements of `source_file` that are considered in the rest of the row\n",
    "- `median`, `mean`, `min`, `max`, `std` are the means of the elements of `source_file` filtered by `holc_grade` and `loc_year`\n",
    "- `num_bounds` is the number of boundaries used to compute the statistics. This may be less than the total number of HOLC boundaries for this grade if some of the boundaries in some scenes are filtered out due to low `pixel_frac`. \n",
    "\n",
    "For example, a few rows of the aggregate file that compute the summary statistics of LST in the Bronx may look like\n",
    "\n",
    "| source_file | holc_grade | loc_year | median | mean | min | max | std |  num_bounds |\n",
    "|-------------|------------|----------|--------|------|-----|-----|-----|-----|\n",
    "| stats_lst_LT05_L1TP_014032_19910621_20160929_01_T1.csv | \"A\" | \"NYBronx1938\" | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |\n",
    "| stats_lst_LT05_L1TP_014032_19910621_20160929_01_T1.csv | \"B\" | \"NYBronx1938\" | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 |\n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |$\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |\n",
    "\n",
    "In this way, two aggregate files are generated: one for LST and one for NDVI. They are exported to `02-data/summary_stats_agg/`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "097b8956-ca48-4767-ae92-7eee7800c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelfrac_filter = 0.9\n",
    "\n",
    "###################################################################################\n",
    "# Get all the summary stats and split into NDVI and LST\n",
    "summary_names=[]\n",
    "helpers.get_filenames(DIR_STATS, summary_names)\n",
    "lst_summary_names = [x for x in summary_names if \"lst\" in x and \"ext\" in x]\n",
    "ndvi_summary_names = [x for x in summary_names if \"ndvi\" in x and \"ext\" in x]\n",
    "\n",
    "holc_grades = [\"A\",\"B\",\"C\",\"D\"]\n",
    "stat_cols = [\"median\",\"mean\",\"min\",\"max\",\"std\",\"pixel_frac\"]\n",
    "loc_years = [\"NYBrooklyn1938\",\"NYBronx1938\",\"NYManhattan1937\",\n",
    "                 \"NYStatenIsland1940\",\"NYQueens1938\"]\n",
    "\n",
    "combined_filenames = [lst_summary_names, ndvi_summary_names]\n",
    "prefix_filenames = [\"ext_lst_filt\"+str(pixelfrac_filter),\n",
    "                    \"ext_ndvi_filt\"+str(pixelfrac_filter)]\n",
    "count = 0\n",
    "for filename_list in combined_filenames:\n",
    "    \n",
    "    df_all_stats = pd.DataFrame(columns=[\"source_file\",\"holc_grade\",\n",
    "                        \"loc_year\",\"median\",\"mean\",\"min\",\"max\",\"std\",\n",
    "                        \"pixel_frac\", \"num_bounds\"])\n",
    "\n",
    "    for filename in filename_list:\n",
    "\n",
    "        df_stats = pd.read_csv(filename)\n",
    "        \n",
    "        \"\"\"\n",
    "        Filter for rows which have a num_pixels_frac greater than a \n",
    "        user-specified value\n",
    "        \"\"\"\n",
    "        df_stats = df_stats[df_stats[\"pixel_frac\"]>pixelfrac_filter]\n",
    "        \n",
    "        # Drop the HOLC Grade E row\n",
    "        df_stats = df_stats[df_stats[\"holc_grade\"]!=\"E\"]\n",
    "\n",
    "        # Compute the mean of all the summary statistics by HOLC grade\n",
    "        # city-wide.\n",
    "        mean_vals_nyc = df_stats.groupby(\"holc_grade\").mean()[stat_cols]\n",
    "        mean_vals_nyc[\"source_file\"] = filename.split(\"/\")[-1]\n",
    "        mean_vals_nyc[\"loc_year\"] = \"NYC\"\n",
    "        mean_vals_nyc[\"num_bounds\"] = df_stats.groupby(\"holc_grade\").count()[\"index\"]\n",
    "        \n",
    "        mean_vals_nyc.reset_index(inplace=True)\n",
    "\n",
    "        df_all_stats = pd.concat([df_all_stats, mean_vals_nyc])\n",
    "\n",
    "        for grade in holc_grades:\n",
    "            # Compute the mean of all the summary statistics by HOLC \n",
    "            # grade by borough.\n",
    "            mean_vals_boros = df_stats[df_stats[\"holc_grade\"]==\n",
    "                            grade].groupby(\"loc_year\").mean()[stat_cols]\n",
    "            mean_vals_boros[\"source_file\"] = filename.split(\"/\")[-1]\n",
    "            mean_vals_boros[\"holc_grade\"] = grade\n",
    "            mean_vals_boros[\"num_bounds\"] = df_stats[df_stats[\"holc_grade\"]==\n",
    "                            grade].groupby(\"loc_year\").count()[\"index\"]\n",
    "            \n",
    "            mean_vals_boros.reset_index(inplace=True)\n",
    "\n",
    "            df_all_stats = pd.concat([df_all_stats, mean_vals_boros])\n",
    "\n",
    "    df_all_stats.to_csv(DIR_STATS_AGG + \"/\"+prefix_filenames[count]+\n",
    "                        \"_mean_stats_combined.csv\", index=False)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117d239f-1feb-4361-a597-884f154b3b9a",
   "metadata": {},
   "source": [
    "Look at the summary files more closely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e9c9a89-da72-49b9-9935-c585c9a32633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements with HOLC A =  678\n",
      "Number of elements with HOLC B =  678\n",
      "Number of elements with HOLC C =  678\n",
      "Number of elements with HOLC D =  678\n"
     ]
    }
   ],
   "source": [
    "summary_names=[]\n",
    "helpers.get_filenames(DIR_STATS_AGG, summary_names)\n",
    "\n",
    "fname = summary_names[-2]\n",
    "\n",
    "df_stats = pd.read_csv(fname)\n",
    "\n",
    "print(\"Number of elements with HOLC A = \", len(df_stats[df_stats[\"holc_grade\"]==\"A\"]))\n",
    "print(\"Number of elements with HOLC B = \", len(df_stats[df_stats[\"holc_grade\"]==\"B\"]))\n",
    "print(\"Number of elements with HOLC C = \", len(df_stats[df_stats[\"holc_grade\"]==\"C\"]))\n",
    "print(\"Number of elements with HOLC D = \", len(df_stats[df_stats[\"holc_grade\"]==\"D\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db9a3e-b166-4cf5-8ee7-1fc85d9145a8",
   "metadata": {},
   "source": [
    "### B. Aggregate statistics Method 2: Group HOLC Boundary by Decade <a id=method2></a>\n",
    "\n",
    "We want to know the mean of the median LST (NDVI) for $\\sim$10 year periods. This suggests that we should compute the average median value of a specific HOLC boundary over that time period so we have a value which represents the expected temperature in that area. We save the result to a row in a dataframe. Repeating this for every time period that we consider, we end up with four files. Each file contains: \n",
    "\n",
    "| source_file | holc_grade | loc_year | median | mean | min | max | std | num_scenes |\n",
    "|-------------|------------|----------|--------|------|-----|-----|-----|-----|\n",
    "| \"name_of_source_file\"| \"grade_to_filtery_by\" | \"boro_to_filter_by\" | mean_of_medians | mean_of_mean | mean_of_min | mean_of_max | mean_of_std | num_scenes |\n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |$\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |\n",
    "\n",
    "- `source_file` specifies the filename containing summary statistics for a single Landsat file. (These are the files exported in Section 1 of this notebook.) \n",
    "- `holc_grade` specifies the selected HOLC elements of `source_file` that are considered in the rest of the row\n",
    "- `loc_year` specifies the selected location elements of `source_file` that are considered in the rest of the row\n",
    "- `median`, `mean`, `min`, `max`, `std` are the means of the elements of `source_file` filtered by `holc_grade` and `loc_year`\n",
    "- `num_scenes` is the number of number of Landsat scenes used to compute the statistic. This may be less than the total number of scenes if there is a cloud over the boundary during one flyover. \n",
    "\n",
    "First, import all the filenames for the extended statistics and group them into the decades we consider. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0f97a8-0506-475e-af14-41985bebac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The year ranges we choose for grouping the data\n",
    "year_ranges = [(1984,1993), (1994,2002), (2003, 2012), (2013,2022)]\n",
    "\n",
    "# fnames_stats is a list of all the extended filenames that we will use\n",
    "fnames_stats = []\n",
    "helpers.get_filenames(DIR_STATS, fnames_stats)\n",
    "fnames_stats_lst = [x for x in fnames_stats if \"lst\" in x and \"ext\" in x]\n",
    "fnames_stats_ndvi = [x for x in fnames_stats if \"ndvi\" in x and \"ext\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6a3fd6-f022-4d2d-989d-1399f364a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelfrac_filter = 0.0 # OPTIONS: Any float >0.0 and <1.0\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "obs_options = [\"lst\",\"ndvi\"]\n",
    "for obs_choice in range(2):\n",
    "    \n",
    "    fnames = [fnames_stats_lst, fnames_stats_ndvi][obs_choice]\n",
    "    fnames_yr = [\n",
    "        [x for x in fnames if \n",
    "             parse_date_fname(x) <= datetime_year(year_ranges[yr][1]) and\n",
    "             parse_date_fname(x) >= datetime_year(year_ranges[yr][0])] for yr in range(4)]\n",
    "    \n",
    "    for yr in range(4):\n",
    "        label = obs_options[obs_choice]\n",
    "\n",
    "        \"\"\"Initialize a dataframe to store all the statistics information\"\"\"\n",
    "        df_stats = pd.read_csv(fnames_yr[yr][0])\n",
    "        df_stats[\"index\"] = df_stats.index\n",
    "\n",
    "        for i in range(1,len(fnames_yr[yr])):\n",
    "            df_yr = pd.read_csv(fnames_yr[yr][i])\n",
    "            df_yr[\"index\"] = df_yr.index\n",
    "            df_stats = pd.concat([df_stats, df_yr])\n",
    "\n",
    "        df_filtered = df_stats[df_stats[\"pixel_frac\"]>pixelfrac_filter]    \n",
    "\n",
    "        \"\"\"Compute the mean value for each HOLC boundary\"\"\"\n",
    "        df_mean_stats = df_filtered.groupby(\"index\").mean()\n",
    "        df_mean_stats[\"num_bounds\"] = df_filtered.groupby(\"index\").count()[\"pixel_frac\"]\n",
    "\n",
    "        df_mean_stats[\"holc_grade\"] = df_yr[\"holc_grade\"]\n",
    "        df_mean_stats[\"loc_year\"] = df_yr[\"loc_year\"]\n",
    "        df_mean_stats[\"geometry\"] = df_yr[\"geometry\"]\n",
    "\n",
    "        df_mean_stats.rename(columns={\"pixelnum\":\"num_pixels\",\n",
    "                                      \"pixelnum_max\":\"max_num_pixels\"}, inplace=True)\n",
    "\n",
    "        exportname = DIR_STATS_T + \"/m2_ext_\"+label+\"_pfilt\"+str(pixelfrac_filter)+\\\n",
    "                    \"_yr\"+str(yr)+\".csv\"\n",
    "        df_mean_stats.to_csv(exportname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf73a62-1625-4f82-82e6-0b1ab88fff57",
   "metadata": {
    "tags": []
   },
   "source": [
    "### C. Aggregate statistics Method 3: Group All HOLC_X Boundaries within a Decade <a id=method3></a>\n",
    "\n",
    "The two ways that we aggregate statistics temporally involve choosing an order in which to take the mean first--either first take the mean for a Landsat scene, or first take the mean for an HOLC boundary. We can avoid this problem if we take the mean of all HOLC_X boundaries within a certain time period. This way, there is no ambiguity about the first choice being made. We save the result to a row in a dataframe. Repeating this for every time period that we consider, we end up with one dataframe that contains `num_holc_grades` $\\times$ `num_year_ranges` $=16$ rows. Each row contains the mean of the summary statistics for every HOLC boundary within that date range.  \n",
    "\n",
    "| year_range | holc_grade | loc_year | median | mean | min | max | std | num_bounds |\n",
    "|------------|------------|----------|--------|------|-----|-----|-----|-----|\n",
    "| \"year_range\" | \"grade_to_filtery_by\" | \"boro_to_filter_by\" | mean_of_medians | mean_of_mean | mean_of_min | mean_of_max | mean_of_std | num_scenes |\n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |$\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |\n",
    "\n",
    "- `year_range` is a string representing the start and end range of the years. Both ends of the range are inclusive.\n",
    "- `holc_grade` specifies the selected HOLC elements of `source_file` that are considered in the rest of the row\n",
    "- `loc_year` specifies the selected location elements of `source_file` that are considered in the rest of the row\n",
    "- `median`, `mean`, `min`, `max`, `std` are the means of the elements of `source_file` filtered by `holc_grade` and `loc_year`\n",
    "- `num_scenes` is the number of number of Landsat scenes used to compute the statistic. This may be less than the total number of scenes if there is a cloud over the boundary during one flyover. \n",
    "\n",
    "First, import all the filenames for the extended statistics and group them into the decades we consider. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4f72686-41a7-4d3e-8476-d94185bc332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The year ranges we choose for grouping the data\n",
    "year_ranges = [(1984,1993), (1994,2002), (2003, 2012), (2013,2022)]\n",
    "\n",
    "# fnames_stats is a list of all the extended filenames that we will use\n",
    "fnames_stats = []\n",
    "helpers.get_filenames(DIR_STATS, fnames_stats)\n",
    "fnames_stats_lst = [x for x in fnames_stats if \"lst\" in x and \"ext\" in x]\n",
    "fnames_stats_ndvi = [x for x in fnames_stats if \"ndvi\" in x and \"ext\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bb8e97a-7974-4b04-9a00-b8339d262788",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelfrac_filter = 0.0 # OPTIONS: Any float >0.0 and <1.0\n",
    "#####################################################################\n",
    "\n",
    "obs_options = [\"lst\",\"ndvi\"]\n",
    "for obs_choice in range(len(obs_options)):\n",
    "    \n",
    "    fnames = [fnames_stats_lst, fnames_stats_ndvi][obs_choice]\n",
    "    fnames_yr = [\n",
    "        [x for x in fnames if \n",
    "             parse_date_fname(x) <= datetime_year(year_ranges[yr][1]) and\n",
    "             parse_date_fname(x) >= datetime_year(year_ranges[yr][0])] for yr in range(4)]\n",
    "    \n",
    "    for yr in range(4):\n",
    "        \n",
    "        \"\"\"Initialize a dataframe to store all the statistics information\"\"\"\n",
    "        df_stats = pd.DataFrame(columns=[\"median\", \"mean\", \"min\", \"max\", \"std\", \"num_pixels\", \n",
    "                \"pixel_frac\", \"num_bounds\", \"year_range\"])\n",
    "        df_mean_stats = df_stats\n",
    "        \n",
    "        label = obs_options[obs_choice]\n",
    "\n",
    "        for i in range(len(fnames_yr[yr])):\n",
    "            df_yr = pd.read_csv(fnames_yr[yr][i])\n",
    "            df_yr[\"index\"] = df_yr.index\n",
    "            df_stats = pd.concat([df_stats, df_yr])\n",
    "\n",
    "        \"\"\"Filter for the fraction of non-nan pixels\"\"\"\n",
    "        df_filtered = df_stats[df_stats[\"pixel_frac\"]>pixelfrac_filter]    \n",
    "\n",
    "        \"\"\"Compute the mean value for each HOLC boundary\"\"\"\n",
    "        df_stats = df_filtered.groupby(\"holc_grade\").mean()\n",
    "        \n",
    "        df_stats[\"num_bounds\"] = df_filtered.groupby(\"holc_grade\").count()[\"index\"]\n",
    "        df_stats[\"year_range\"] = str(year_ranges[yr][0])+\"-\"+str(year_ranges[yr][1])\n",
    "        \n",
    "        df_mean_stats = pd.concat([df_mean_stats, df_stats])\n",
    "        \n",
    "        df_mean_stats.drop(columns=\"index\", inplace=True)\n",
    "        df_mean_stats.reset_index(inplace=True)\n",
    "        df_mean_stats.rename(columns={\"index\":\"holc_grade\"}, inplace=True)\n",
    "\n",
    "        exportname = DIR_STATS_T + \"/m3_ext_\"+label+\\\n",
    "                \"_pfilt\"+str(pixelfrac_filter)+\"_yr\"+str(yr)+\".csv\"\n",
    "        df_mean_stats.to_csv(exportname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85ea3b96-de9a-4419-bdd6-6c6c36e7d6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holc_grade</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>num_pixels</th>\n",
       "      <th>pixel_frac</th>\n",
       "      <th>num_bounds</th>\n",
       "      <th>year_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.192411</td>\n",
       "      <td>0.198662</td>\n",
       "      <td>0.017585</td>\n",
       "      <td>0.440174</td>\n",
       "      <td>0.079608</td>\n",
       "      <td>740.479167</td>\n",
       "      <td>0.999718</td>\n",
       "      <td>336</td>\n",
       "      <td>2013-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.169966</td>\n",
       "      <td>0.181830</td>\n",
       "      <td>0.014838</td>\n",
       "      <td>0.442464</td>\n",
       "      <td>0.079454</td>\n",
       "      <td>1060.802910</td>\n",
       "      <td>0.990518</td>\n",
       "      <td>1512</td>\n",
       "      <td>2013-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>0.146621</td>\n",
       "      <td>0.155716</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.435332</td>\n",
       "      <td>0.071452</td>\n",
       "      <td>1306.640967</td>\n",
       "      <td>0.995750</td>\n",
       "      <td>3969</td>\n",
       "      <td>2013-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>0.131143</td>\n",
       "      <td>0.144512</td>\n",
       "      <td>-0.005376</td>\n",
       "      <td>0.433890</td>\n",
       "      <td>0.080162</td>\n",
       "      <td>1189.813926</td>\n",
       "      <td>0.981115</td>\n",
       "      <td>2499</td>\n",
       "      <td>2013-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>0.132810</td>\n",
       "      <td>0.138691</td>\n",
       "      <td>-0.024122</td>\n",
       "      <td>0.497762</td>\n",
       "      <td>0.094203</td>\n",
       "      <td>725.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>2013-2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  holc_grade    median      mean       min       max       std   num_pixels  \\\n",
       "0          A  0.192411  0.198662  0.017585  0.440174  0.079608   740.479167   \n",
       "1          B  0.169966  0.181830  0.014838  0.442464  0.079454  1060.802910   \n",
       "2          C  0.146621  0.155716  0.003968  0.435332  0.071452  1306.640967   \n",
       "3          D  0.131143  0.144512 -0.005376  0.433890  0.080162  1189.813926   \n",
       "4          E  0.132810  0.138691 -0.024122  0.497762  0.094203   725.000000   \n",
       "\n",
       "   pixel_frac num_bounds year_range  \n",
       "0    0.999718        336  2013-2022  \n",
       "1    0.990518       1512  2013-2022  \n",
       "2    0.995750       3969  2013-2022  \n",
       "3    0.981115       2499  2013-2022  \n",
       "4    1.000000         21  2013-2022  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_mean_stats.drop(columns=[\"index\",\"level_0\"], inplace=True)\n",
    "df_mean_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b055fa-1466-4ce4-8266-9fef7d04acea",
   "metadata": {},
   "source": [
    "### D. Aggregate statistics Method 4: Group Raw Data by Year Range <a id=method4></a>\n",
    "\n",
    "Instead of taking the mean of the medians, group all the raw statistics data and include a column for the decade considered. In this way, we output one large `CSV` file for LST and another for NDVI.\n",
    "\n",
    "| year_range | holc_grade | loc_year | median | mean | min | max | std |\n",
    "|------------|------------|----------|--------|------|-----|-----|-----|\n",
    "| \"year_range\" | \"grade_to_filtery_by\" | \"boro_to_filter_by\" | mean_of_medians | mean_of_mean | mean_of_min | mean_of_max | mean_of_std | \n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ |$\\vdots$ | $\\vdots$ | $\\vdots$ | $\\vdots$ | \n",
    "\n",
    "- `year_range` is a string representing the start and end range of the years. Both ends of the range are inclusive.\n",
    "- `holc_grade` specifies the selected HOLC elements of `source_file` that are considered in the rest of the row\n",
    "- `loc_year` specifies the selected location elements of `source_file` that are considered in the rest of the row\n",
    "- `median`, `mean`, `min`, `max`, `std` are the means of the elements of `source_file` filtered by `holc_grade` and `loc_year`\n",
    "\n",
    "First, import all the filenames for the extended statistics and group them into the decades we consider. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33ca6577-222a-4ca2-a562-f51d24d4b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The year ranges we choose for grouping the data\n",
    "year_ranges = [(1984,1993), (1994,2002), (2003, 2012), (2013,2022)]\n",
    "\n",
    "# fnames_stats is a list of all the extended filenames that we will use\n",
    "fnames_stats = []\n",
    "helpers.get_filenames(DIR_STATS, fnames_stats)\n",
    "fnames_stats_lst = [x for x in fnames_stats if \"lst\" in x and \"ext\" in x]\n",
    "fnames_stats_ndvi = [x for x in fnames_stats if \"ndvi\" in x and \"ext\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c3b8834-e5fa-46ee-a387-e3e974790f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelfrac_filter = 0.0 # OPTIONS: Any float >0.0 and <1.0\n",
    "#####################################################################\n",
    "\n",
    "obs_options = [\"lst\",\"ndvi\"]\n",
    "\n",
    "for obs_choice in range(len(obs_options)):\n",
    "    \n",
    "    fnames = [fnames_stats_lst, fnames_stats_ndvi][obs_choice]\n",
    "    fnames_yr = [\n",
    "        [x for x in fnames if \n",
    "             parse_date_fname(x) <= datetime_year(year_ranges[yr][1]) and\n",
    "             parse_date_fname(x) >= datetime_year(year_ranges[yr][0])] for yr in range(4)]\n",
    "\n",
    "    for yr in range(4):\n",
    "        \"\"\"Initialize a dataframe to store all the statistics information\"\"\"\n",
    "        df_stats = pd.DataFrame(columns=[\"landsat_id\",\"median\", \"mean\", \"min\", \"max\", \"std\", \"num_pixels\", \n",
    "                \"pixel_frac\", \"year_range\"])\n",
    "        df_mean_stats = df_stats\n",
    "        \n",
    "        label = obs_options[obs_choice]\n",
    "\n",
    "        for i in range(len(fnames_yr[yr])):\n",
    "            df_yr = pd.read_csv(fnames_yr[yr][i])\n",
    "            df_yr[\"index\"] = df_yr.index\n",
    "            df_yr[\"landsat_id\"] = fnames_yr[yr][i].split(\"/\")[-1].split(label)[1][1:-4]\n",
    "            df_stats = pd.concat([df_stats, df_yr])\n",
    "\n",
    "        \"\"\"Filter for the fraction of non-nan pixels\"\"\"\n",
    "        df_filtered = df_stats[df_stats[\"pixel_frac\"]>pixelfrac_filter].copy()\n",
    "\n",
    "        \"\"\"Add year range column\"\"\"\n",
    "        df_filtered[\"year_range\"] = str(year_ranges[yr][0])+\"-\"+str(year_ranges[yr][1])\n",
    "        \n",
    "        df_mean_stats = pd.concat([df_mean_stats, df_filtered])\n",
    "\n",
    "        exportname = DIR_STATS_T + \"/m4_ext_\"+label+\\\n",
    "                \"_pfilt\"+str(pixelfrac_filter)+\"_yr\"+str(yr)+\".csv\"\n",
    "        df_mean_stats.to_csv(exportname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c33a91-33b1-470c-a8c1-b07571852149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
